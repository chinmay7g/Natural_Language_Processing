{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get documents from wikipedia pages\n",
    "\n",
    "import wikipedia\n",
    "\n",
    "def pages_to_sentences(*pages):\n",
    "    sentences = []\n",
    "    for page in pages:\n",
    "        p = wikipedia.page(page)\n",
    "        doc = nlp(p.content)\n",
    "        sentences += [sent.text for sent in doc.sents]\n",
    "    return sentences\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_docs = pages_to_sentences('Reticulated python', 'Ball python')\n",
    "language_docs = pages_to_sentences('Python(programming language)')\n",
    "\n",
    "documents = animal_docs + language_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<833x2730 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8776 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bag_of_words = CountVectorizer()\n",
    "bag_of_words.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 224)\t1\n",
      "  (0, 275)\t1\n",
      "  (0, 960)\t1\n",
      "  (0, 1234)\t1\n",
      "  (0, 1327)\t1\n",
      "  (0, 1498)\t1\n",
      "  (0, 1648)\t1\n",
      "  (0, 1964)\t1\n",
      "  (0, 1967)\t1\n",
      "  (0, 2085)\t1\n",
      "  (0, 2087)\t1\n",
      "  (0, 2281)\t1\n",
      "  (0, 2304)\t1\n",
      "  (0, 2305)\t1\n",
      "  (0, 2315)\t1\n",
      "  (0, 2477)\t2\n",
      "  (0, 2510)\t1\n",
      "  (1, 224)\t1\n",
      "  (1, 274)\t1\n",
      "  (1, 339)\t1\n",
      "  (1, 587)\t1\n",
      "  (1, 780)\t1\n",
      "  (1, 1327)\t1\n",
      "  (1, 1332)\t1\n",
      "  (1, 1344)\t1\n",
      "  :\t:\n",
      "  (824, 1328)\t1\n",
      "  (825, 51)\t1\n",
      "  (825, 1523)\t1\n",
      "  (825, 2412)\t1\n",
      "  (826, 1234)\t1\n",
      "  (826, 1923)\t1\n",
      "  (826, 1964)\t1\n",
      "  (827, 71)\t1\n",
      "  (827, 825)\t1\n",
      "  (828, 160)\t1\n",
      "  (828, 1916)\t1\n",
      "  (828, 2658)\t1\n",
      "  (829, 77)\t1\n",
      "  (829, 114)\t1\n",
      "  (829, 129)\t1\n",
      "  (829, 1328)\t1\n",
      "  (831, 950)\t1\n",
      "  (831, 1448)\t1\n",
      "  (832, 289)\t1\n",
      "  (832, 672)\t1\n",
      "  (832, 1396)\t1\n",
      "  (832, 1727)\t1\n",
      "  (832, 1923)\t1\n",
      "  (832, 1964)\t1\n",
      "  (832, 2648)\t1\n"
     ]
    }
   ],
   "source": [
    "#retreiving word count\n",
    "\n",
    "word_counts = bag_of_words.transform(documents)\n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2510)\t0.11599144900454125\n",
      "  (0, 2477)\t0.20100144395657732\n",
      "  (0, 2315)\t0.2681013567782279\n",
      "  (0, 2305)\t0.3146696844212807\n",
      "  (0, 2304)\t0.3010109635319611\n",
      "  (0, 2281)\t0.21034869918498691\n",
      "  (0, 2087)\t0.2744412305363544\n",
      "  (0, 2085)\t0.1966899782956673\n",
      "  (0, 1967)\t0.3339205702856944\n",
      "  (0, 1964)\t0.10467934874613\n",
      "  (0, 1648)\t0.2744412305363544\n",
      "  (0, 1498)\t0.2904164365262395\n",
      "  (0, 1327)\t0.1305421923594814\n",
      "  (0, 1234)\t0.11949145088240319\n",
      "  (0, 960)\t0.3339205702856944\n",
      "  (0, 275)\t0.3010109635319611\n",
      "  (0, 224)\t0.10411299777865861\n",
      "  (1, 2699)\t0.26201169433579435\n",
      "  (1, 2677)\t0.2552058205111456\n",
      "  (1, 2477)\t0.1869133815229277\n",
      "  (1, 2281)\t0.19560549362077578\n",
      "  (1, 2016)\t0.2700613345478498\n",
      "  (1, 1735)\t0.17305214033265062\n",
      "  (1, 1722)\t0.1125882008324717\n",
      "  (1, 1472)\t0.2700613345478498\n",
      "  :\t:\n",
      "  (824, 66)\t0.5462801292136648\n",
      "  (825, 2412)\t0.6412512790621154\n",
      "  (825, 1523)\t0.5577072152930828\n",
      "  (825, 51)\t0.5270288977952121\n",
      "  (826, 1964)\t0.3971212653031109\n",
      "  (826, 1923)\t0.7979982926507624\n",
      "  (826, 1234)\t0.4533138268027179\n",
      "  (827, 825)\t0.6448904541963434\n",
      "  (827, 71)\t0.764275017311461\n",
      "  (828, 2658)\t0.5773502691896257\n",
      "  (828, 1916)\t0.5773502691896257\n",
      "  (828, 160)\t0.5773502691896257\n",
      "  (829, 1328)\t0.4489744095450226\n",
      "  (829, 129)\t0.4489744095450226\n",
      "  (829, 114)\t0.5462801292136648\n",
      "  (829, 77)\t0.5462801292136648\n",
      "  (831, 1448)\t0.7196580719127579\n",
      "  (831, 950)\t0.6943286394286294\n",
      "  (832, 2648)\t0.505114782083608\n",
      "  (832, 1964)\t0.15834629889771937\n",
      "  (832, 1923)\t0.31819015300402115\n",
      "  (832, 1727)\t0.43930697328392176\n",
      "  (832, 1396)\t0.2881884982231908\n",
      "  (832, 672)\t0.505114782083608\n",
      "  (832, 289)\t0.2955610981064856\n"
     ]
    }
   ],
   "source": [
    "# training the TfIdf for weights\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "weights = tfidf.fit_transform(word_counts)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0330862217988015 zope\n",
      "7.0330862217988015 incubation\n",
      "7.0330862217988015 giving\n",
      "7.0330862217988015 gnu\n",
      "7.0330862217988015 goal\n",
      "7.0330862217988015 gottlob\n",
      "7.0330862217988015 gradual\n",
      "7.0330862217988015 grammar\n",
      "7.0330862217988015 grams\n",
      "7.0330862217988015 greatest\n",
      "7.0330862217988015 greatly\n",
      "7.0330862217988015 gripped\n",
      "7.0330862217988015 gripping\n",
      "7.0330862217988015 groovy\n",
      "7.0330862217988015 growing\n",
      "7.0330862217988015 grown\n",
      "7.0330862217988015 grumpy\n",
      "7.0330862217988015 guard\n",
      "7.0330862217988015 guide\n"
     ]
    }
   ],
   "source": [
    "#checking the weights in order of weightage\n",
    "\n",
    "top_idf_indices = tfidf.idf_.argsort()[:-20:-1]\n",
    "ind_to_word = bag_of_words.get_feature_names()\n",
    "\n",
    "for ind in top_idf_indices:\n",
    "    print(tfidf.idf_[ind], ind_to_word[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as observed, words appearing very rarely have been given equal weightage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
